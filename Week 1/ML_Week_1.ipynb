{"cells":[{"cell_type":"markdown","metadata":{"id":"eFg7aL7BqPex"},"source":["# Objectives\n","\n"]},{"cell_type":"markdown","source":["\n","* To introduce you to 3 of the main (Python-based) libraries we'll be using throughout the module:\n","> 1. scikit-learn (https://scikit-learn.org/stable/) - one of the well-used machine learning libraries.\n","> 2. numpy (https://numpy.org/) -  a very common library for mathematical tasks.\n","> 3. matplotlib (https://matplotlib.org/) - for creating plots.\n",">**Note**: It is your responsibility as a machine learning scientist to read documentations for any library function you use and to thoroughly understand what it is doing, if it validly serves your purpose, and which of its parameters you need to consider.\n","\n","* To explore the basic linear model and L1 and L2 regularization from Week 1 lecture\n","\n","* To see some of the basic components of machine learning first hand - training data, training labels, test data, test labels, machine learning model (with weights and biases being the primary parameters that specify a model for most machine learning algorithms), model evaluation & performance - and some of the basic steps of the machine learning pipeline:\n",">1. Data sourcing - today, we'll simply generate data using a random number generator.\n",">2. Model building using training data & based on chosen machine learning algorithm(s) - linear regression (the basic linear model) is the very simplest algorithm.\n",">3. Model evaluation - our performance metric today is the mean squared error (same formula as the L2 loss).\n",">**Note** - A measure of model performance is referred to as 'loss' when the goal is to optimize the model parameters, but as '(performance) metric' when the goal is simply to analyze how well the model performs (especially on unseen data).\n","\n","* To highlight to you the important principle of reproducibility\n"],"metadata":{"id":"g8f4eGPFVUaz"}},{"cell_type":"markdown","metadata":{"id":"hsv7Ks_9qPe1"},"source":["# Section 1 - Set up imports and random number generator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bibkBao6qPe1"},"outputs":[],"source":["%matplotlib inline\n","\n","import numpy\n","from sklearn import linear_model\n","from sklearn.metrics import mean_squared_error\n","import matplotlib.pyplot as plt\n","\n","\n","# Set up the random number generator\n","rng =  numpy.random.default_rng()"]},{"cell_type":"markdown","metadata":{"id":"SS3p1FHFqPe4"},"source":["# Section 2 - Train linear regression model 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7VG1xu2MqPe5"},"outputs":[],"source":["# Generate random data between 0 and 1\n","# with number of data instances (n) = 10\n","# number of features (d) = 1\n","# number of labels = 1\n","training_data_x = rng.random((10, 1))\n","training_labels_y = rng.random((10, 1))\n","\n","print('A randomly generated n x d input data where n=10 and d=1:')\n","print(training_data_x)\n","\n","# Train a linear regression model\n","lr_model_1 = linear_model.LinearRegression()\n","lr_model_1.fit(training_data_x, training_labels_y)\n","print(\"\\nThe weight (w):\",  lr_model_1.coef_)\n","print(\"The bias (b):\",  lr_model_1.intercept_)\n","\n","# Check the performance of the model on the data used to train it\n","training_pred_y = lr_model_1.predict(training_data_x)\n","print(\"\\nMean squared error (error on training data): %.2f \" % mean_squared_error(training_labels_y, training_pred_y))\n","\n","\n"]},{"cell_type":"markdown","source":["# Section 3 - Plot linear regression model 1"],"metadata":{"id":"eQaPiq1oP0mO"}},{"cell_type":"code","source":["# Plot data and model\n","plt.scatter(training_data_x, training_labels_y, color=\"blue\")\n","plt.plot(training_data_x, training_pred_y, color=\"black\", linewidth=3)\n","\n","plt.xlabel('x', size=20)\n","plt.ylabel('y', size=20)\n","plt.title('Linear regression model 1 visualization \\n', size=20)\n","\n","plt.show()"],"metadata":{"id":"U1bHFBY4P2Ta"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 4 - Train linear regression model 2"],"metadata":{"id":"FqTOU6qpuyRd"}},{"cell_type":"code","source":["# Generate random data between 0 and 1\n","# with number of data instances (n) = 100\n","# number of features (d) = 20\n","# number of labels = 1\n","training_data_x = rng.random((100, 20))\n","training_labels_y = rng.random((100, 1))\n","\n","# Train a linear regression model\n","lr_model_2 = linear_model.LinearRegression()\n","lr_model_2.fit(training_data_x, training_labels_y)\n","print(\"\\nThe weights (w):\",  lr_model_2.coef_)\n","print(\"\\nThe bias (b):\",  lr_model_2.intercept_)\n","\n","# Check the performance of the model on the data used to train it\n","training_pred_y = lr_model_2.predict(training_data_x)\n","print(\"\\nMean squared error (training error): %.2f \" % mean_squared_error(training_labels_y, training_pred_y))\n","\n"],"metadata":{"id":"_l9XfyeLsxr2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Reflections"],"metadata":{"id":"XAmcTJuGTa7_"}},{"cell_type":"markdown","source":["\n","\n","*   Why are the 20 weights for model 2, but only one for model 1?\n","*   Why is there one bias for both models?\n","\n"],"metadata":{"id":"qDMXHuw5TaFe"}},{"cell_type":"markdown","metadata":{"id":"lPe4tiZ8qPe6"},"source":["# Section 5 - Evaluate linear regression model 2"]},{"cell_type":"markdown","source":["*   Generate a new data instance to evaluate model 2\n","*   What is the mean squared error obtained for this instance?\n","\n"],"metadata":{"id":"RgMNi6U6Um5l"}},{"cell_type":"markdown","source":["# Section 6 - Explore the effects of L1 and L2 regularization"],"metadata":{"id":"eXBbTaUsWp9x"}},{"cell_type":"markdown","source":["*   Generate new training and test data\n","*   Train and evaluate a linear regression model\n","  * See above examples; also see https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n","*   Train and evaluate a linear regression model with L2 regularization\n","  * Set alpha to 0.5\n","  * See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html#sklearn.linear_model.Ridge)\n","*   Train and evaluate a linear regression model with L1 regularization\n","  * Set alpha to 0.5\n","  * See https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn.linear_model.Lasso)\n","*   What are the effects of regularization that you notice?\n","  * See Week 1 lecture\n","  * Hint - Compare the weights (and bias) and the errors.\n","\n","\n"],"metadata":{"id":"Kgt_0IwhW2HZ"}},{"cell_type":"markdown","metadata":{"id":"x4cKOMKXqPe7"},"source":["# Section 7 - Explore reproducibility\n"]},{"cell_type":"markdown","source":["* Run Section 2 code multiple times (e.g. 3 times) - each time, copy and paste your outputs (training data, weight, bias, mean squared error) somewhere so that you can compare outputs across the multiple runs. What do you notice? What is the implication, and how could you address it?"],"metadata":{"id":"KIPtsaBlfeDi"}},{"cell_type":"markdown","source":["# Section 8 - Explore the effect of alpha on L1 and L2 regularization"],"metadata":{"id":"NS8-6nL6dzi3"}},{"cell_type":"markdown","source":["* Using your code in Section 6, compare the effect of multiple alpha values, e.g. alpha = 0.000000001, 0.0001, 0.1, on regularization."],"metadata":{"id":"avIg1Nmsd7hq"}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"provenance":[],"collapsed_sections":["eFg7aL7BqPex","hsv7Ks_9qPe1","SS3p1FHFqPe4","eQaPiq1oP0mO","FqTOU6qpuyRd","XAmcTJuGTa7_","lPe4tiZ8qPe6","eXBbTaUsWp9x","x4cKOMKXqPe7","NS8-6nL6dzi3"]}},"nbformat":4,"nbformat_minor":0}