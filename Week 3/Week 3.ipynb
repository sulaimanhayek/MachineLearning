{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["rxyl5fPn1cEU","kPvpMsQb3JN7","ZNQnWrTL1uFN","oHjsZ1d3NYCP","dlxoG_76etp6","JK-55bd7wDPE","ZPZlfnwlTsle","e1EuTj3KpxQo"],"authorship_tag":"ABX9TyNTfF/iNcAb2YuqtjbE8n86"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Objectives"],"metadata":{"id":"rxyl5fPn1cEU"}},{"cell_type":"markdown","source":["\n","* To explore an existing dataset\n","> This week, we'll use a subset of the UK Met dataset. You can read more about the UK Met dataset here: https://rmets.onlinelibrary.wiley.com/doi/10.1002/gdj3.78. We will use the 60km-resolution data for 2010 to 2022.\n","\n","* To apply support vector machine (SVM) and logistic regression algorithms from Week 3 lecture to automatic detection of the number of days of ground frost and snow based on other weather variables."],"metadata":{"id":"qCCRn5I21gF8"}},{"cell_type":"markdown","source":["# Section 1 - Explore the UK Met (60km, 2010-2022) dataset"],"metadata":{"id":"kPvpMsQb3JN7"}},{"cell_type":"markdown","source":["See the dataset on the Week 3 page for the module, on Canvas (see 'Week 3 Lab Dataset' on the page). The file is named c*urated_data_1month_2010-2022_nonans.csv*.\n","* What does each variable in the dataset represent?\n","* What is the distribution of the number of days of ground frost in the dataset? What of for the number of days of snow?\n","* What does this tell you about the data?\n","* What else can you tell about the data?\n"],"metadata":{"id":"DiO4BnO_-szF"}},{"cell_type":"markdown","source":["# Section 2 - Load the dataset\n","\n"],"metadata":{"id":"ZNQnWrTL1uFN"}},{"cell_type":"markdown","source":["\n","\n","1. You need to first download the data before you can get started. Download from the Week 3 page for the module, on Canvas (see 'Week 3 Lab Dataset' on the page). The file you download will be named *curated_data_1month_2010-2022_nonans.csv*.\n","\n","2. Then, use the file menu in Google Colab to upload the file to your Colab directory. Once upload is complete, you should be able to see the file on the listed contents of your Colab directory.\n","\n","3. You can now run the code in the cell below to load the data."],"metadata":{"id":"KXj3aE3e2dHy"}},{"cell_type":"code","source":["import csv\n","import numpy\n","\n","\n","!ls  /content\n","\n","data_file_full_path = \"/content/curated_data_1month_2010-2022_nonans.csv\"\n","\n","data_as_list = []\n","\n","# load the dataset\n","with open(data_file_full_path) as csv_file:\n","    csv_reader = csv.reader(csv_file, delimiter=',')\n","\n","    row_count = 0\n","    for row in csv_reader:\n","\n","      if row_count > 0:\n","        data_as_list.append([float(val) for val in row])\n","      row_count += 1\n","data = numpy.array(data_as_list)\n","\n","# check its shape\n","print(\"\\n The dataset has shape: \"+str(data.shape))\n","\n","\n","# get features and labels from the data\n","# based on the objectives (see the Objectives section)\n","feat_col = [5, 6, 7, 8, 9, 10, 11]\n","ground_frost_col = 4\n","snow_col = 12\n","\n","feats = data[:, feat_col]\n","ground_frost_label = data[:, ground_frost_col]\n","snow_label = data[:, snow_col]\n","\n","\n","# take a peek\n","print(\"\\n A peek at the dataset features: \\n\"+str(feats))\n","print(\"\\n A peek at the ground frost labels: \\n\"+str(ground_frost_label))\n","print(\"\\n A peek at the snow labels: \\n\"+str(snow_label))\n"],"metadata":{"id":"0gFnB9nq4yWz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 3 - Split into training, validation, and test sets"],"metadata":{"id":"oHjsZ1d3NYCP"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","all_ids = numpy.arange(0, feats.shape[0])\n","\n","random_seed = 1\n","\n","# First randomly split the data into 70:30 to get the training set\n","train_set_ids, rem_set_ids = train_test_split(all_ids, test_size=0.3, train_size=0.7,\n","                                 random_state=random_seed, shuffle=True)\n","\n","\n","# Then further split the remaining data 50:50 into validation and test sets\n","val_set_ids, test_set_ids = train_test_split(rem_set_ids, test_size=0.5, train_size=0.5,\n","                                 random_state=random_seed, shuffle=True)\n","\n","\n","train_data = feats[train_set_ids, :]\n","train_ground_frost_labels = ground_frost_label[train_set_ids]\n","train_snow_labels = snow_label[train_set_ids]\n","\n","val_data = feats[val_set_ids, :]\n","val_ground_frost_labels = ground_frost_label[val_set_ids]\n","val_snow_labels = snow_label[val_set_ids]\n","\n","test_data = feats[test_set_ids, :]\n","test_ground_frost_labels = ground_frost_label[test_set_ids]\n","test_snow_labels = snow_label[test_set_ids]"],"metadata":{"id":"pFYBM9RBSMDS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 4 - Train and evaluate a SVM regression model (with hyperparameter optimization)"],"metadata":{"id":"dlxoG_76etp6"}},{"cell_type":"code","source":["\n","from sklearn.svm import LinearSVR\n","from sklearn.metrics import mean_squared_error\n","import sys\n","\n","#--- Use the validation set to optimize the box constraint hyperparameter ---\n","#--- based on grid search method ---\n","\n","# set the range of hyperparameters to search from\n","c_options = [0.1, 1.0, 10.0]\n","# initialize the optimal box constraint value\n","best_c = 0.1\n","# initialize the performance of the optimal box constraint value\n","best_c_perf = sys.float_info.max\n","\n","# for each box constraint in the set of values to search\n","# training a SVM model and evaluate it\n","# if the performance obtained is better than the currrent 'best_c_perf'\n","# set the box constraint as the current optimal\n","for c in c_options:\n","  #print(\"\\n for c=\"+str(c)+\"...\")\n","  model_SVM = LinearSVR(C=c, random_state=random_seed, loss='squared_epsilon_insensitive')\n","  model_SVM.fit(train_data, train_ground_frost_labels)\n","  val_pred_SVM = model_SVM.predict(val_data)\n","  val_mse_SVM = mean_squared_error(val_ground_frost_labels, val_pred_SVM)\n","\n","  if val_mse_SVM < best_c_perf:\n","    best_c = c\n","    best_c_perf = val_mse_SVM\n","\n","print('\\n The optimal c for this data is: '+str(best_c))\n","\n","\n","# use the optimized box constraint to train the final model\n","model_SVM = LinearSVR(C=best_c, random_state=random_seed, loss='squared_epsilon_insensitive')\n","model_SVM.fit(train_data, train_ground_frost_labels)\n","\n","# evaluate the trained model using the test set\n","test_pred_SVM = model_SVM.predict(test_data)\n","mse_SVM = mean_squared_error(test_ground_frost_labels, test_pred_SVM)\n","print('\\n The test mean squared error (MSE) is: '+str(mse_SVM))\n","\n"],"metadata":{"id":"sETTFPn0HBCL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Section 5 - Train and evaluate with scaled features"],"metadata":{"id":"JK-55bd7wDPE"}},{"cell_type":"markdown","source":["* Read the StandardScaler documentation (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). Using the documentation above, compute scaled features from *feats* in Section 2 based on standard scaling.\n","\n","* Train and evaluate the SVM model with the scaled features.\n","\n","* What differences do you notice in the feature distribution and the results?\n"],"metadata":{"id":"hZiydO8NR11u"}},{"cell_type":"markdown","source":["# Section 6 - Train and evaluate a LR classification model"],"metadata":{"id":"ZPZlfnwlTsle"}},{"cell_type":"markdown","source":["* Use the information from Section 1 to split the ground frost label values into 4 classes.\n","* Apply this to create classification labels for the labels in Section 2.\n","* Use the classification labels to train and evaluate a logistic regression model using the Scikit Learn library (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n"],"metadata":{"id":"gBxV3dKuUadG"}},{"cell_type":"markdown","source":["# Section 7 - Evaluate using other classification metrics"],"metadata":{"id":"e1EuTj3KpxQo"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score, confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n","\n","# F1 score similar to accuracy in that it ranges between 0 and 1\n","# We will look at this metric in Weeks 5-6\n","avg_f1_score_LR = f1_score(test_ground_frost_labels_class, test_pred_LR, average='macro')\n","f1_scores_LR = f1_score(test_ground_frost_labels_class, test_pred_LR, average=None)\n","print('\\n The F1 scores for each of the classes are: '+str(f1_scores_LR))\n","print('\\n The average F1 score is: '+str(avg_f1_score_LR))\n","print()\n","\n","# Confusion shows the misclassification\n","# We will look at this metric in Weeks 5-6\n","confusion_matrix_SVM = confusion_matrix(test_ground_frost_labels_class, test_pred_LR)\n","disp = ConfusionMatrixDisplay(confusion_matrix_SVM)\n","disp.plot()\n","plt.show()\n"],"metadata":{"id":"jQHmDopxb0q9"},"execution_count":null,"outputs":[]}]}